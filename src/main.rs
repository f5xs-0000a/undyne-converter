#![feature(io_error_more)]

mod folder_dance;

use core::{
    hash::Hasher,
    mem::drop,
};
use std::{
    ffi::OsStr,
    fs::{
        metadata,
        remove_dir_all,
    },
    io::{
        ErrorKind,
        Read as _,
        Result as IoResult,
        Seek as _,
    },
    process::Stdio,
};
use std::{
    fs::OpenOptions,
    io::{
        BufRead as _,
        BufReader,
    },
    // this trait import automatically assumes that it will work for Unix-based
    // operating systems and not Windows
    os::unix::process::CommandExt as _,
    path::{
        Path,
        PathBuf,
    },
    process::Command,
};

use clap::Parser;
use libc::{
    getpid,
    setsid,
};
use nix::{
    sys::signal::{
        kill,
        Signal,
    },
    unistd::{
        // until Rust stabilizes chown, we're importing this from nix
        chown,
        geteuid,
        Gid,
        Pid,
        Uid,
    },
};
use rustc_hash::FxHasher;

use crate::folder_dance::generate_random_string;

#[derive(PartialEq, Parser)]
enum App {
    Dump,
    Restore,
}

#[derive(PartialEq, Eq, Hash, Debug, Clone, Copy)]
struct JobId(u64);

impl core::fmt::LowerHex for JobId {
    fn fmt(
        &self,
        f: &mut std::fmt::Formatter,
    ) -> Result<(), core::fmt::Error> {
        self.0.fmt(f)
    }
}

fn main() {
    use App::*;

    if !geteuid().is_root() {
        eprintln!("User is not root. Have you tried running using sudo?");
        return;
    }

    let mode = App::parse();
}

impl Drop for ConversionJob {
    fn drop(&mut self) {
        // kill without regards
        if let Some(pid) = self.pid {
            drop(kill(pid, Signal::SIGKILL));

            // remove the working path
            drop(remove_dir_all(self.working_path()));
        }
    }
}

fn get_sudo_invoker_gid() -> Gid {
    match std::env::var("SUDO_GID") {
        Ok(uid) => {
            match uid.parse::<u32>() {
                Ok(uid) => Gid::from_raw(uid),
                Err(e) => panic!("Cannot parse {} into i32: {:?}", uid, e),
            }
        },
        Err(e) => panic!("Cannot find the sudo-invoking user: {:?}", e),
    }
}

fn get_sudo_invoker() -> Uid {
    match std::env::var("SUDO_UID") {
        Ok(uid) => {
            match uid.parse::<u32>() {
                Ok(uid) => Uid::from_raw(uid),
                Err(e) => panic!("Cannot parse {} into i32: {:?}", uid, e),
            }
        },
        Err(e) => panic!("Cannot find the sudo-invoking user: {:?}", e),
    }
}

fn get_sudo_invoker_name() -> String {
    match std::env::var("SUDO_USER") {
        Ok(uid) => uid,
        Err(e) => panic!("Cannot find the sudo-invoking user: {:?}", e),
    }
}

pub struct ConversionJob {
    /// The path to the media being converted.
    path: PathBuf,

    /// The ID of the process.
    ///
    /// Obtained from the system. If this is a `None`, then the object is a
    /// dummy.
    pid: Option<Pid>,

    /// The ID of the job.
    ///
    /// Generated by this program.
    job_id: JobId,

    #[doc(hidden)]
    base_path: Option<PathBuf>,
}

impl ConversionJob {
    /// Creates a new job. Used mostly for debugging purposes.
    fn new_with_base_path(
        file_path: &(impl AsRef<Path> + AsRef<OsStr> + ?Sized),
        uid: Uid,
        base_path: Option<PathBuf>,
    ) -> IoResult<ConversionJob> {
        let job_id = JobId(read_file_get_hash(file_path)?);

        // create a dummy Job object for now
        let dummy = ConversionJob {
            job_id,
            path: PathBuf::new(),
            pid: None,
            base_path: base_path.clone(),
        };

        let working_path = dummy.create_working_path()?;

        let stderr_name = working_path.join("stderr.log");
        let stdout_name = working_path.join("stdout.log");

        let stderr = OpenOptions::new()
            .create(true)
            .write(true)
            .open(stderr_name)
            .unwrap();
        let stdout = OpenOptions::new()
            .create(true)
            .write(true)
            .open(stdout_name)
            .unwrap();

        let spawned = unsafe {
            Command::new("ffmpeg")
            .arg("-hide_banner")
            .arg("-i")
            .arg(&file_path)
            .arg("-vn")
            .arg("-filter:a")
            .arg("loudnorm=print_format=json")
            .arg("-f")
            .arg("null")
            .arg("/dev/null")
            // set the user ID into the caller's
            .uid(uid.into())
            // we have to detach the process from the tty so criu doesn't
            // have to complain that the process we're trying to restore does
            // not have a tty included
            // to do that, set all stdin, stdout, and stderr to null
            .stdin(Stdio::null())
            .stdout(stdout)
            .stderr(stderr)
            // criu also complains, if the process restored is not a shell job
            // (related above), and the process is not its own session leader
            .pre_exec(|| {
                setsid();
                // Make the command the leader of the new session
                libc::setpgid(0, getpid());
                Ok(())
            })
            .spawn()
            .unwrap()
        };

        let real_job = ConversionJob {
            pid: Some(Pid::from_raw(spawned.id() as i32)),
            path: <_ as AsRef<Path>>::as_ref(file_path).to_path_buf(),
            job_id,
            base_path,
        };

        // create the folders
        std::fs::create_dir_all(real_job.working_path())?;

        Ok(real_job)
    }

    pub fn new(
        file_path: &(impl AsRef<Path> + AsRef<OsStr> + ?Sized),
        uid: Uid,
    ) -> IoResult<ConversionJob> {
        ConversionJob::new_with_base_path(file_path, uid, None)
    }

    /// Obtain the base path.
    ///
    /// The hierarchy of paths go like this:
    /// base
    /// ├─ job
    /// │  ├─ working
    /// │  ├─ saved_working
    /// │  └─ dump
    /// ├─ job
    /// ...
    ///
    /// The base path is relative to the invoking user's home directory.
    fn base_path(&self) -> PathBuf {
        if let Some(base_path) = &self.base_path {
            return base_path.to_path_buf();
        }

        let mut path = PathBuf::from("/");
        path.push("home");
        path.push(get_sudo_invoker_name());
        path.push(".criu");
        path
    }

    /// Obtain the path of the job.
    ///
    /// The hierarchy of paths go like this:
    /// base
    /// ├─ job
    /// │  ├─ working
    /// │  ├─ saved_working
    /// │  └─ dump
    /// ├─ job
    /// ...
    ///
    /// The job path is the directory where the files and directories required
    /// to perform and restore a job is located.
    fn job_path(&self) -> PathBuf {
        let mut path = self.base_path();
        path.push(format!("{:x}", self.job_id.0));
        path
    }

    /// Obtain the working path of a job.
    ///
    /// The hierarchy of paths go like this:
    /// base
    /// ├─ job
    /// │  ├─ working
    /// │  ├─ saved_working
    /// │  └─ dump
    /// ├─ job
    /// ...
    ///
    /// The working path is the directory where the files being read and/or
    /// written by the job's process are located.
    fn working_path(&self) -> PathBuf {
        let mut path = self.job_path();
        path.push("working");
        path
    }

    /// Create the working path (using `working_path()`) and set its owner to
    /// the appropriate user.
    fn create_working_path(&self) -> IoResult<PathBuf> {
        let path = self.working_path();

        // create the folders
        std::fs::create_dir_all(&path)?;

        // set the owner
        chown(
            &path,
            Some(get_sudo_invoker()),
            Some(get_sudo_invoker_gid()),
        );

        Ok(path)
    }

    /// Obtain the saved-working path of a job.
    ///
    /// The hierarchy of paths go like this:
    /// base
    /// ├─ job
    /// │  ├─ working
    /// │  ├─ saved_working
    /// │  └─ dump
    /// ├─ job
    /// ...
    ///
    /// The saved-working path is similar to the working path, except that
    /// when the process state is dumped into the dump path, so to are the files
    /// in the working path copied into saved_working.
    fn saved_working_path(&self) -> PathBuf {
        let mut path = self.job_path();
        path.push("saved_working");
        path
    }

    /// obtain the dumping path of the job
    ///
    /// the hierarchy of paths go like this:
    /// base
    /// ├─ job
    /// │  ├─ working
    /// │  ├─ saved_working
    /// │  └─ dump
    /// ├─ job
    /// ...
    ///
    /// The dump path is the directory where the files required to restore the
    /// job is located.
    fn dump_path(&self) -> PathBuf {
        let mut path = self.job_path();
        path.push("dump");
        path
    }

    /// Performed upon finishing a job.
    fn on_finish(&self) {}

    /// Generates a name for a temporary dumping directory without creating
    /// said directory.
    ///
    /// TODO: move this to folder dance
    fn create_temp_dump_dir_name(&self) -> PathBuf {
        let mut path = self.job_path();
        path.push(format!("dump-{}", generate_random_string()));
        path
    }

    /// Create a temporary dumping directory and
    /// This method will be mostly used by the dump method.
    fn create_temp_dump_dir(&self) -> IoResult<PathBuf> {
        let temp_dir = self.create_temp_dump_dir_name();
        std::fs::create_dir_all(&temp_dir)?;
        Ok(temp_dir)
    }

    /// Dump the state of the program into a file
    pub fn dump(&self) -> IoResult<()> {
        // create the temporary folder to put the new dump into
        let temp_path = self.create_temp_dump_dir()?;
        std::fs::create_dir(&temp_path);

        // TODO: how do you check if the process really still exists?

        // pause the job
        let status = Command::new("criu")
            .arg("dump")
            .arg("--tree")
            .arg(&format!("{}", self.pid.as_ref().unwrap()))
            .arg("--images-dir")
            .arg(&temp_path)
            .arg("--leave-stopped")
            .output()
            .unwrap();

        // see if the job was really paused
        if status.status.code() != Some(0) {
            panic!(
                "Job failed to be paused: {:?}",
                String::from_utf8(status.stderr).unwrap()
            );
        }

        // continue the job
        kill(self.pid.as_ref().cloned().unwrap(), Signal::SIGCONT).unwrap();

        // folder dance:
        // 1. dump into new folder
        // 2. copy old working area into a new name
        // 3. rename old dump into a new folder
        // 4. rename old working area into a new name
        // 5. rename new dump as the dump folder
        // 6. rename new working area
        // 7. delete old dump and old working area
        // this ensures that the amount of time that the proper dump path is
        // not a valid directory containing valid dump files is minimal
        //
        // we've done step 1 from this point.
        
        // step 2
        let new_working =
            folder_dance::copy_area_into_new_name(&self.working_path())
                .unwrap();
        // step 3
        let old_dump =
            folder_dance::rename_to_appended_random_returning_new_name(
                &self.dump_path(),
            );

        // step 4
        let old_working =
            folder_dance::rename_to_appended_random_returning_new_name(
                &self.saved_working_path(),
            );

        // step 5
        std::fs::rename(&temp_path, self.dump_path());

        // step 6
        std::fs::rename(&new_working, self.saved_working_path());

        // step 7
        if let Ok(old_dump) = old_dump {
            remove_dir_all(&old_dump);
        }
        if let Ok(old_working) = old_working {
            remove_dir_all(&old_working);
        }

        Ok(())
    }

    fn restore_with_base_path(
        // TODO: this should just be a job ID. implement it when you've got
        // the database finished.
        file_path: &(impl AsRef<Path> + ?Sized),
        base_path: Option<PathBuf>,
    ) -> IoResult<ConversionJob> {
        // TODO: you should get the job ID from the database vvvvvvvvvvvvvvvvvvv
        let job_id = JobId(read_file_get_hash(file_path)?);

        // create a dummy Job object for now
        let dummy = ConversionJob {
            job_id,
            path: PathBuf::new(),
            base_path: base_path.clone(),

            // NOTE: do not rely on this. this is only a placeholder.
            pid: None,
        };
        // TODO: you should get the job ID from the database ^^^^^^^^^^^^^^^^^^^

        // create the file at which to write the PID into
        let mut pid_filename = dummy.job_path();
        pid_filename.push("pidfile.txt");

        // delete the pid file if it exists.
        // criu doesn't like it when it exists.
        core::mem::drop(std::fs::remove_file(&pid_filename));

        assert!(dummy.dump_path().exists());
        dbg!(&pid_filename);

        // resume the job
        let x = Command::new("criu")
            .arg("restore")
            .arg("--images-dir")
            .arg(dummy.dump_path())
            .arg("--restore-detached")
            .arg("--pidfile")
            .arg(&pid_filename)
            .output()
            .unwrap();

        eprintln!("{}", String::from_utf8(x.stdout).unwrap());
        eprintln!("{}", String::from_utf8(x.stderr).unwrap());

        // read the contents of the PID file
        let pid_file =
            OpenOptions::new().read(true).open(&pid_filename).unwrap();
        let mut pid_str = String::new();
        BufReader::new(pid_file).read_line(&mut pid_str).unwrap();
        pid_str.pop();

        // TODO: raise a manual IoError upon read failure
        let pid = pid_str.parse::<i32>().unwrap();
        let pid = Pid::from_raw(pid);

        kill(pid, None);

        // delete the pid file if it exists.
        // criu doesn't like it when it exists.
        core::mem::drop(std::fs::remove_file(pid_filename));

        let job = ConversionJob {
            pid: Some(pid),
            path: <_ as AsRef<Path>>::as_ref(file_path).to_path_buf(),
            job_id,
            base_path,
        };
        Ok(job)
    }

    pub fn restore(
        // TODO: this should just be a job ID. implement it when you've got
        // the database finished.
        file_path: &(impl AsRef<Path> + ?Sized),
    ) -> IoResult<ConversionJob> {
        ConversionJob::restore_with_base_path(file_path, None)
    }
}

/// Reads a file to get its hash.
///
/// The file is not read in its entirety to save computation time and I/O time.
/// Instead, the file is read this way:
/// ```
/// hasher(head(file, 65536))
/// hasher(tail(file, 65536))*
/// hasher(size(file))
/// ```
///
/// If the file's length is less than 65536 * 2, tail will not read the
/// overlapping bytes.
fn read_file_get_hash(path: &(impl AsRef<Path> + ?Sized)) -> IoResult<u64> {
    use std::io::SeekFrom::{
        End,
        Start,
    };

    // get the file size
    let filesize = std::fs::metadata(path)?.len();

    // open the file for reading
    let mut file = OpenOptions::new().read(true).open(path)?;

    // NOTE: If in case of security concerns, feel free to replace the hash
    // function by something much more sensible.
    let mut hasher = FxHasher::default();

    // hash the first 65536 bytes
    {
        let mut buffer = vec![0u8; 65536];
        let bytes_read = file.read(&mut buffer)?;

        buffer.truncate(bytes_read);

        hasher.write(&buffer);
    }

    // hash the file size
    hasher.write_u64(filesize);

    // hash the last 65536 bytes. do not overlap if the file is too small
    if 65536 < filesize {
        if filesize < 65536 * 2 {
            file.seek(Start(65536)).unwrap();
        }
        else {
            file.seek(End(-65536)).unwrap();
        }

        let mut buffer = vec![0u8; 65536];
        let bytes_read = file.read(&mut buffer)?;

        buffer.truncate(bytes_read);

        hasher.write(&buffer);
    }

    Ok(hasher.finish())
}

#[cfg(test)]
mod test {
    use std::os::unix::fs::MetadataExt as _;

    use crate::*;

    #[test]
    fn folder_dance_works() {
        // create procedure to automatically drop the test bed upon end
        struct DropTestDir(PathBuf);
        impl Drop for DropTestDir {
            fn drop(&mut self) {
                drop(std::fs::remove_dir_all(&self.0));
            }
        }

        macro_rules! assert_path {
            ($PATH:expr) => {{
                let path = PathBuf::from(&$PATH);
                assert!(path.exists());
                path.metadata().unwrap()
            }};

            ($PATH:expr,) => { assert_path!($PATH) };

            ($PATH:expr, FOLDER true $(, $MORE:ident $ARGS:expr)*) => {{
                let metadata = assert_path!($PATH $(, $MORE $ARGS)*);
                assert!(metadata.is_dir());
                metadata
            }};

            ($PATH:expr, FILE true $(, $MORE:ident $ARGS:expr)*) => {{
                let metadata = assert_path!($PATH $(, $MORE $ARGS)*);
                assert!(metadata.is_file());
                metadata
            }};

            ($PATH:expr, UID $UID:expr $(, $MORE:ident $ARGS:expr)*) => {{
                let metadata = assert_path!($PATH $(, $MORE $ARGS)*);
                assert_eq!(metadata.uid(), $UID);
                metadata
            }};
        }

        if !geteuid().is_root() {
            panic!(
                "Tester isn't root. Have you tried running this test as root?"
            );
        }

        let invoker = get_sudo_invoker().as_raw();

        let path = "./src/test_files/Coffee Run.webm";
        let testing_base_path = PathBuf::from("/tmp/criu_test");

        // start the converter
        let converter = ConversionJob::new_with_base_path(
            path,
            get_sudo_invoker(),
            Some(testing_base_path.clone()),
        )
        .unwrap();

        // drop the test path once dropped
        let _x = DropTestDir(testing_base_path);

        // Stage 1: After starting job
        // └ base
        //   └ job
        //     └ working
        // the UID of the working path should be the invoker's
        assert_path!(converter.job_path(), FOLDER true, UID 0);

        // start dumping the job
        converter.dump().unwrap();

        // Stage 2: After dumping
        // assert that these exist
        // └ base
        //   └ job
        //     ├ dump
        //     │ ├ files.img (f)
        //     │ ├ inventory.img (f)
        //     │ ├ pages-1.img (f)
        //     │ ├ pstree.img (f)
        //     │ ├ seccomp.img (f)
        //     │ └ stats-dump (f)
        //     ├ saved_working
        //     └ working
        let files = [
            "files.img",
            "inventory.img",
            "pages-1.img",
            "pstree.img",
            "seccomp.img",
            "stats-dump",
        ];
        let saved_working_path_meta = assert_path!(
            converter.saved_working_path(),
            FOLDER true,
            UID invoker
        );
        assert_path!(
            converter.working_path(),
            FOLDER true,
            UID invoker
        );
        let dump_path_meta = assert_path!(
            converter.dump_path(),
            FOLDER true,
            UID 0
        );
        for file in files.iter() {
            let file = converter.dump_path().join(file);
            assert_path!(file, FILE true, UID 0);
        }

        let job_path = converter.job_path();
        let dump_path = converter.dump_path();
        let working_path = converter.working_path();
        let saved_working_path = converter.saved_working_path();

        // drop the converter. we don't need that one.
        drop(converter);

        // Stage 3: After dropping the job.
        // assert that these exist
        // └ base
        //   └ job
        //     ├ dump
        //     │ ├ files.img (f)
        //     │ ├ inventory.img (f)
        //     │ ├ pages-1.img (f)
        //     │ ├ pstree.img (f)
        //     │ ├ seccomp.img (f)
        //     │ └ stats-dump (f)
        //     └ saved_working
        assert_path!(job_path, FOLDER true, UID 0);
        assert_path!(dump_path, FOLDER true, UID 0);
        assert_path!(saved_working_path, FOLDER true, UID invoker);
        for file in files.iter() {
            let file = dump_path.join(file);
            assert_path!(file, FILE true, UID 0);
        }
        // the interesting part here is that the working path SHOULD NOT exist
        assert!(!working_path.exists());

        // restore the job
        let converter = ConversionJob::restore(&path).unwrap();

        // Stage 4: After restoring the job.
        // assert that these exist
        // └ base
        //   └ job
        //     ├ dump
        //     │ ├ files.img (f)
        //     │ ├ inventory.img (f)
        //     │ ├ pages-1.img (f)
        //     │ ├ pstree.img (f)
        //     │ ├ seccomp.img (f)
        //     │ └ stats-dump (f)
        //     ├ saved_working
        //     └ working
        assert_path!(converter.job_path(), FOLDER true, UID 0);
        assert_path!(converter.dump_path(), FOLDER true, UID 0);
        assert_path!(converter.saved_working_path(), FOLDER true, UID invoker);
        assert_path!(converter.working_path(), FOLDER true, UID invoker);
        for file in files.iter() {
            let file = converter.dump_path().join(file);
            assert_path!(file, FILE true, UID 0);
        }

        // dump it again
        converter.dump();

        // Stage 5: After dumping again
        // assert that these exist
        // └ base
        //   └ job
        //     ├ dump
        //     │ ├ files.img (f)
        //     │ ├ inventory.img (f)
        //     │ ├ pages-1.img (f)
        //     │ ├ pstree.img (f)
        //     │ ├ seccomp.img (f)
        //     │ └ stats-dump (f)
        //     ├ saved_working
        //     └ working
        // also assert that the creation/modified date of the dump and
        // saved_working folders are later than the original
        let files = [
            "files.img",
            "inventory.img",
            "pages-1.img",
            "pstree.img",
            "seccomp.img",
            "stats-dump",
        ];
        assert_path!(
            converter.saved_working_path(),
            FOLDER true,
            UID invoker
        );
        assert_path!(
            converter.working_path(),
            FOLDER true,
            UID invoker
        );
        assert_path!(converter.dump_path(), FOLDER true, UID 0);
        for file in files.iter() {
            let file = converter.dump_path().join(file);
            assert_path!(file, FILE true, UID 0);
        }

        // let the dropper do its job
    }
}
